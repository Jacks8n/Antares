// here a hybrid eulerian-lagrangian scheme is implemented, specifically a tailored mls-mpm [Hu et al. 2018].
// refer to the links below for detail:
//  - original mls-mpm paper: https://www.yzhu.io/projects/siggraph18_mlsmpm_cpic/index.html
//  - implementation examples: https://nialltl.neocities.org/articles/mpm_guide.html
//
// as for the sparse data structure, there are various choices, e.g., octree, vdb, spgrid.
// after some comparisons, i used something similar to the gspgrid as the sparse data structure.
// some references are available:
//  - original spgrid paper: https://pages.cs.wisc.edu/~sifakis/project_pages/SPGrid.html
//  - gpu optimization of mpm: https://doi.org/10.1145/3272127.3275044
//      - where gspgrid and some inspirng optimization are introduced
//  - taichi programming language: https://doi.org/10.1145/3355089.3356506
//      - special thanks to their benchmarks!
//  - original vdb paper: http://dx.doi.org/10.1145/2487228.2487235
//  - nanovdb implementation: https://github.com/AcademySoftwareFoundation/openvdb/blob/feature/nanovdb/nanovdb/nanovdb/nanovdb/NanoVDB.h

// todo
// 1. scaffold crud
//  1.1 create: add particles with distribution(cube, sphere, particle list, etc.)
//  1.2 delete: remove particles with predicates(volume, property criteria)
//  1.3 retrieve: query particles' properties(lifetime, material, etc.), collision detection
//  1.4 update: update particles' properties
// 2. test affine momentum
// 3. rendering fluids

#pragma use_dxc
// #pragma enable_d3d11_debug_symbols

#pragma kernel GenerateIndirectArgs0
#pragma kernel GenerateIndirectArgs1
#pragma kernel GenerateParticleHistogram
#pragma kernel GenerateParticleOffsets
#pragma kernel SortParticles
#pragma kernel ParticleToGrid0
#pragma kernel ParticleToGrid1
#pragma kernel SolveGridLevel0
#pragma kernel SolveGridLevel1
#pragma kernel GridToParticle
#pragma kernel ClearFluidGridLevel0
#pragma kernel ClearFluidGridLevel1
#pragma kernel AddParticles

#include "FluidData.cginc"
#include "HLSLSupport.cginc"
#include "../Graphics/SDFUtil.cginc"

#define DISABLE_WAVE_SCATTER 0

/// begin constant buffer

CBUFFER_START(PhysicsSceneParameters)
    float3 SceneVolumeTexel;
    #define SCENE_VOLUME_TEXEL SceneVolumeTexel

    float FluidGridSpacing;
CBUFFER_END

CBUFFER_START(PhysicsFrameParameters)
    // when the time step is 0, inverse of it should be 0 too
    float2 TimeStep;
    #define TIME_STEP TimeStep.x
    #define TIME_STEP_INV TimeStep.y

    uint CurrentFrameAddParticleCount;

    float Padding1;

    float3 FluidGravity;
    #define GLOBAL_GRAVITY FluidGravity

    float Padding2;

    float3 FluidGridTranslation;

    float Padding3;

    float3 FluidGridToSDF;
CBUFFER_END

/// end constant buffer

/// begin internal data/funcs

extern RWBuffer<uint> FluidParticlePropertiesPool;

uint GetPooledParticlePropertyCountOffset()
{
    return 0;
}

uint GetPooledParticlePropertyOffset(uint index)
{
    return GetPooledParticlePropertyCountOffset() + 1 + index;
}

uint GetPooledParticlePropertyCount()
{
    const uint offset = GetPooledParticlePropertyCountOffset();
    return FluidParticlePropertiesPool.Load(offset);
}

void SetPooledParticlePropertyCount(uint count)
{
    const uint offset = GetPooledParticlePropertyCountOffset();
    FluidParticlePropertiesPool[offset] = count;
}

uint GetPooledParticleProperty(uint index)
{
    const uint offset = GetPooledParticlePropertyOffset(index);
    return FluidParticlePropertiesPool.Load(offset);
}

void SetPooledParticleProperty(uint index, uint propertyIndex)
{
    const uint offset = GetPooledParticlePropertyOffset(index);
    FluidParticlePropertiesPool[offset] = propertyIndex;
}

uint AllocatePooledParticleProperties(uint count)
{
    uint lo;
    const uint offset = GetPooledParticlePropertyCountOffset();
    InterlockedAdd(FluidParticlePropertiesPool[offset], count, lo);

    return lo;
}

float3 Square(float3 x)
{
    return x * x;
}

float Pow4(float x)
{
    x *= x;
    x *= x;
    return x;
}

float3 GetGridSpacePosition(float3 worldSpacePosition)
{
    return (worldSpacePosition - FluidGridTranslation) * FluidGridSpacing;
}

int3 GetKernelMinGridIndex(float3 gridSpacePosition)
{
    return int3(ceil(gridSpacePosition - 1.5));
}

bool IsGridInBound(int3 gridIndex)
{
    return all(gridIndex >= 0 & gridIndex < FLUID_VIRTUAL_GRID_EXTENT);
}

/// end internal data/funcs

/// begin sort particle

#define GENERATE_PARTICLE_HISTOGRAM_KERNEL_SIZE 128

groupshared uint BlockAllocationCountLevel1_GSM;
groupshared uint3 BlockAllocationLevel1_GSM[GENERATE_PARTICLE_HISTOGRAM_KERNEL_SIZE];
groupshared uint BlockAllocationCountLevel0_GSM;
groupshared uint3 BlockAllocationLevel0_GSM[GENERATE_PARTICLE_HISTOGRAM_KERNEL_SIZE];
groupshared uint3 GridPositionsLevel1_GSM[GENERATE_PARTICLE_HISTOGRAM_KERNEL_SIZE];
groupshared uint PooledParticleProperty_GSM[GENERATE_PARTICLE_HISTOGRAM_KERNEL_SIZE];
groupshared uint PooledParticlePropertyCount_GSM;
groupshared uint PooledParticlePropertyOffset_GSM;

groupshared uint BlockAllocationOffset_GSM;

[numthreads(GENERATE_PARTICLE_HISTOGRAM_KERNEL_SIZE, 1, 1)]
void GenerateParticleHistogram(uint3 tid : SV_DispatchThreadID, uint3 gid : SV_GroupID, uint gi : SV_GroupIndex)
{
    if (!gi)
    {
        BlockAllocationCountLevel0_GSM = 0;
        BlockAllocationCountLevel1_GSM = 0;
        PooledParticlePropertyCount_GSM = 0;
    }

    GroupMemoryBarrierWithGroupSync();

    const bool pingpongFlag = !GetFluidParticlePositionPingPongFlag();
    const uint particleCount = GetFluidParticleCount();

    const uint groupIndex = gid.x;
    const uint particleIndex = groupIndex * GENERATE_PARTICLE_HISTOGRAM_KERNEL_SIZE + gi;
    bool valid = particleIndex < particleCount;

    const ParticlePositionIndexed position = GetFluidParticlePosition(particleIndex, pingpongFlag);

    // find level 1 blocks to allocate
    uint3 gridPositionLevel1;
    uint3 gridPositionLevel2;
    uint3 gridOffsetLevel1;
    if (valid)
    {
        const int3 gridPositionLevel0 = GetKernelMinGridIndex(position.Position);
        valid = IsGridInBound(gridPositionLevel0);

        if (valid)
        {
            GetFluidGridPositions(gridPositionLevel0, gridPositionLevel1, gridPositionLevel2, gridOffsetLevel1);

            uint acquired = 1;
            InterlockedCompareExchange(FluidGridLevel2[gridPositionLevel2], 0, 1, acquired);

            if (!acquired)
            {
                uint index;
                InterlockedAdd(BlockAllocationCountLevel1_GSM, 1, index);
                BlockAllocationLevel1_GSM[index] = gridPositionLevel2;
            }

            // allocate adjacent level 1 blocks
            uint i;
            UNITY_UNROLL
            for (i = 1; i < 8; i++)
            {
                const uint3 adjacentGridIndex = uint3(i << 1, i, i >> 1) & 2;
                const uint3 adjacentGridPositionLevel0 = adjacentGridIndex + gridPositionLevel0;

                uint3 adjacentGridPositionLevel1;
                uint3 adjacentGridPositionLevel2;
                uint3 _;
                GetFluidGridPositions(
                    adjacentGridPositionLevel0, adjacentGridPositionLevel1,
                    adjacentGridPositionLevel2, _);

                if (all(adjacentGridPositionLevel2 == gridPositionLevel2))
                    continue;

                acquired = 1;
                InterlockedCompareExchange(FluidGridLevel2[adjacentGridPositionLevel2], 0, 1, acquired);

                if (!acquired)
                {
                    uint index;
                    InterlockedAdd(BlockAllocationCountLevel1_GSM, 1, index);
                    BlockAllocationLevel1_GSM[index] = adjacentGridPositionLevel2;
                }
            }
        }
        else
        {
            // pool properties of particles that are out of bound
            uint offset;
            InterlockedAdd(PooledParticlePropertyCount_GSM, 1, offset);
            PooledParticleProperty_GSM[offset] = position.Index;
        }
    }

    GroupMemoryBarrierWithGroupSync();

    if (!gi)
    {
        // allocate pool
        PooledParticlePropertyOffset_GSM = AllocatePooledParticleProperties(PooledParticlePropertyCount_GSM);

        // allocate level 1 blocks
        InterlockedAdd(FluidBlockParticleOffsets[GetFluidBlockCountOffset(1)], BlockAllocationCountLevel1_GSM, BlockAllocationOffset_GSM);
    }

    GroupMemoryBarrierWithGroupSync();

    // write pooled particle properties to uav
    if (gi < PooledParticlePropertyCount_GSM)
        SetPooledParticleProperty(PooledParticlePropertyOffset_GSM + gi, PooledParticleProperty_GSM[gi]);

    // update level 2 grids
    if (gi < BlockAllocationCountLevel1_GSM)
    {
        uint _;
        InterlockedExchange(
            FluidGridLevel2[BlockAllocationLevel1_GSM[gi]],
            EncodeFluidBlockIndex(BlockAllocationOffset_GSM + gi), _);
    }

    GroupMemoryBarrierWithGroupSync();

    // find level 0 blocks to allocate
    uint3 gridIndexLevel1;
    if (valid)
    {
        uint blockIndexLevel1Linear;
        do
        {
            InterlockedOr(FluidGridLevel2[gridPositionLevel2], 0, blockIndexLevel1Linear);
        } while (!IsValidFluidBlockIndex(blockIndexLevel1Linear));
        blockIndexLevel1Linear = DecodeFluidBlockIndex(blockIndexLevel1Linear);

        gridIndexLevel1 = GetFluidBlockIndexSpatialLevel1(blockIndexLevel1Linear) * FLUID_BLOCK_SIZE_LEVEL1 + gridOffsetLevel1;

        uint acquired = 1;
        InterlockedCompareExchange(FluidGridLevel1[gridIndexLevel1], 0, 1, acquired);

        if (!acquired)
        {
            uint index;
            InterlockedAdd(BlockAllocationCountLevel0_GSM, 1, index);
            BlockAllocationLevel0_GSM[index] = gridIndexLevel1;
            GridPositionsLevel1_GSM[index] = gridPositionLevel1;
        }
    }

    GroupMemoryBarrierWithGroupSync();

    // allocate level 0 blocks
    if (!gi)
        InterlockedAdd(FluidBlockParticleOffsets[GetFluidBlockCountOffset(0)], BlockAllocationCountLevel0_GSM, BlockAllocationOffset_GSM);

    GroupMemoryBarrierWithGroupSync();

    // update level 1 grids
    if (gi < BlockAllocationCountLevel0_GSM)
    {
        uint _;

        const uint blockIndexLevel0Linear = BlockAllocationOffset_GSM + gi;
        uint offset = GetFluidBlockParticleCountOffset(blockIndexLevel0Linear);
        InterlockedExchange(FluidBlockParticleOffsets[offset], 0, _);

        InterlockedExchange(
            FluidGridLevel1[BlockAllocationLevel0_GSM[gi]],
            EncodeFluidBlockIndex(blockIndexLevel0Linear), _);

        offset = GetFluidBlockPositionOffset(blockIndexLevel0Linear);

        const uint3 gridPosition = GridPositionsLevel1_GSM[gi];
        FluidBlockParticleOffsets[offset] = gridPosition.x;
        FluidBlockParticleOffsets[offset +1] = gridPosition.y;
        FluidBlockParticleOffsets[offset +2] = gridPosition.z;
    }

    GroupMemoryBarrierWithGroupSync();

    // add particles to level 0 blocks
    if (valid)
    {
        uint blockIndexLevel0Linear;
        do
        {
            InterlockedOr(FluidGridLevel1[gridIndexLevel1], 0, blockIndexLevel0Linear);
        } while (!IsValidFluidBlockIndex(blockIndexLevel0Linear));
        blockIndexLevel0Linear = DecodeFluidBlockIndex(blockIndexLevel0Linear);

        const uint particleCountOffset = GetFluidBlockParticleCountOffset(blockIndexLevel0Linear);

        uint index;
        InterlockedAdd(FluidBlockParticleOffsets[particleCountOffset], 1, index);
    }
}

#define GENERATE_PARTICLE_OFFSETS_KERNEL_SIZE 128
#define MAX_PARTITION_SIZE (GENERATE_PARTICLE_OFFSETS_KERNEL_SIZE * 8)
#define PARTITION_VALUE_NULL (~0u)

// layout: { partition count, { partition sum, global inclusive sum }* }
// initial value: { 0, { null, null }*  }
extern RWBuffer<uint> PartitionSums;

uint PreemptPartition()
{
    uint partitionIndex;
    InterlockedAdd(PartitionSums[0], 1, partitionIndex);
    return partitionIndex;
}

uint GetPartitionCount()
{
    return PartitionSums[0];
}

uint GetPartitionSumOffset(uint partitionIndex)
{
    return partitionIndex * 2 + 1;
}

uint GetPartitionInclusiveSumOffset(uint partitionIndex)
{
    return partitionIndex * 2 + 2;
}

void SetPartitionValue(uint offset, uint value)
{
    uint _;
    InterlockedExchange(PartitionSums[offset], value, _);
}

uint GetPartitionValue(uint offset)
{
    uint value;
    InterlockedOr(PartitionSums[offset], 0, value);

    return value;
}

uint GetParticleCountLastFrame()
{
    const uint partitionCount = GetPartitionCount();
    if (partitionCount)
        return GetPartitionInclusiveSumOffset(partitionCount - 1);
    else
        return 0;
}

groupshared uint PartitionIndex_GSM;
groupshared uint BlockIndexOffset_GSM;
groupshared uint PartitionSize_GSM;
// WaveGetLaneCount() guarantees that 4~128 lanes are presented
// see https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/wavegetlanecount
// thus additional 1/3(calculated by taking limit) size is reserved for hierarchical sum
groupshared uint ParticleCounts_GSM[MAX_PARTITION_SIZE + MAX_PARTITION_SIZE / 3];
groupshared uint GlobalExclusiveSum_GSM;

[numthreads(GENERATE_PARTICLE_OFFSETS_KERNEL_SIZE, 1, 1)]
void GenerateParticleOffsets(uint3 tid : SV_DispatchThreadID, uint gi : SV_GroupIndex)
{
    if (!gi)
    {
        PartitionIndex_GSM = PreemptPartition();
        BlockIndexOffset_GSM = PartitionIndex_GSM * MAX_PARTITION_SIZE;

        const uint blockCount = GetFluidBlockCount(0);
        PartitionSize_GSM = min(blockCount - BlockIndexOffset_GSM, MAX_PARTITION_SIZE);
    }

    GroupMemoryBarrierWithGroupSync();

    const uint laneIndex = WaveGetLaneIndex();
    const uint laneCount = WaveGetLaneCount();
    const bool isFirstLane = WaveIsFirstLane();
    // kernel size is assumed to be power of 2
    const uint kernelSize = GENERATE_PARTICLE_OFFSETS_KERNEL_SIZE;
    const uint waveCount = (PartitionSize_GSM + laneCount - 1) / laneCount;
    // max partition size is assumed to be larger than 128
    const uint maxWaveCount = MAX_PARTITION_SIZE / laneCount;

    // read particle counts to gsm
    uint i, j;
    for (i = gi; i < PartitionSize_GSM; i += kernelSize)
    {
        const uint particleCount = GetFluidBlockParticleCount(BlockIndexOffset_GSM + i);
        ParticleCounts_GSM[i] = particleCount;
    }

    for (i = gi + PartitionSize_GSM; i < MAX_PARTITION_SIZE; i += kernelSize)
    {
        ParticleCounts_GSM[i] = 0;
    }

    GroupMemoryBarrierWithGroupSync();

    // hierarchical group sum
    uint waveSumSrcOffset;
    uint waveSumDstOffset = 0;
    for (i = MAX_PARTITION_SIZE; i > 1; i /= laneCount)
    {
        waveSumSrcOffset = waveSumDstOffset;
        waveSumDstOffset += i;

        for (j = gi; j < i; j += kernelSize)
        {
            const uint waveParticleCount = WaveActiveSum(ParticleCounts_GSM[j + waveSumSrcOffset]);
            if (isFirstLane)
                ParticleCounts_GSM[j / laneCount + waveSumDstOffset] = waveParticleCount;
        }

        GroupMemoryBarrierWithGroupSync();
    }

    const uint partitionSum = ParticleCounts_GSM[waveSumDstOffset];

    // write group sum to uav
    if (!gi)
    {
        SetPartitionValue(GetPartitionSumOffset(PartitionIndex_GSM), partitionSum);

        // used in the hierarchical exclusive prefix sum below
        ParticleCounts_GSM[waveSumDstOffset] = 0;
    }

    // look back to calculate exclusive prefix sum
    if (gi < laneCount)
    {
        for (i = laneIndex; i - laneIndex < PartitionIndex_GSM; i += laneCount)
        {
            // look back with polling
            uint lookbackSum = 0;
            bool hasInclusiveSum;
            while (true)
            {
                // until `if` here, no divergence is within the wave
                if (i < PartitionIndex_GSM)
                {
                    const uint lookbackIndex = PartitionIndex_GSM - i - 1;

                    const uint lookbackInclusiveSum = GetPartitionValue(GetPartitionInclusiveSumOffset(lookbackIndex));
                    // lane order is reversed in look-back window
                    const uint4 inclusiveSumMask = WaveActiveBallot(lookbackInclusiveSum != PARTITION_VALUE_NULL);
                    const bool4 isInclusiveSumReady = inclusiveSumMask;

                    const int4 inclusiveSumLane4 = isInclusiveSumReady ? firstbitlow(inclusiveSumMask) + int4(0, 32, 64, 96) : int(128).xxxx;
                    const int minInclusiveSumLane = min(min(inclusiveSumLane4.x, inclusiveSumLane4.y), min(inclusiveSumLane4.z, inclusiveSumLane4.w));
                    hasInclusiveSum = minInclusiveSumLane < 128;

                    if (laneIndex < minInclusiveSumLane)
                        lookbackSum = GetPartitionValue(GetPartitionSumOffset(lookbackIndex));

                    if (laneIndex == minInclusiveSumLane)
                        GlobalExclusiveSum_GSM = lookbackInclusiveSum;
                }

                // stop polling if all the lanes have retrieved required value
                const uint4 sumMask = WaveActiveBallot(lookbackSum == PARTITION_VALUE_NULL);
                if (!any(sumMask))
                    break;
            }

            const uint waveSum = WaveActiveSum(lookbackSum);
            if (isFirstLane)
                GlobalExclusiveSum_GSM += waveSum;

            if (hasInclusiveSum)
                break;
        }
    }

    if (isFirstLane)
        SetPartitionValue(GetPartitionInclusiveSumOffset(PartitionIndex_GSM), partitionSum + GlobalExclusiveSum_GSM);
    
    GroupMemoryBarrierWithGroupSync();

    // hierarchical exclusive prefix sum
    for (i = waveSumDstOffset -waveSumSrcOffset; i <= MAX_PARTITION_SIZE; i *= laneCount)
    {
        for (j = gi; j < i; j += kernelSize)
        {
            const uint exclusiveSum = WavePrefixSum(ParticleCounts_GSM[j + waveSumSrcOffset]);
            const uint prevWaveExclusiveSum = ParticleCounts_GSM[j / laneCount + waveSumDstOffset];

            ParticleCounts_GSM[j + waveSumSrcOffset] = GlobalExclusiveSum_GSM + prevWaveExclusiveSum + exclusiveSum;
        }

        waveSumDstOffset = waveSumSrcOffset;
        waveSumSrcOffset -= i;

        GroupMemoryBarrierWithGroupSync();
    }

    for (i = gi; i < PartitionSize_GSM; i += kernelSize)
    {
        SetFluidBlockParticleCountPrefixSum(BlockIndexOffset_GSM + i, ParticleCounts_GSM[i]);
    }
}

#define SORT_PARTICLES_KERNEL_SIZE 128

[numthreads(SORT_PARTICLES_KERNEL_SIZE, 1, 1)]
void SortParticles(uint3 gid : SV_GroupID, uint gi : SV_GroupIndex)
{
    const bool pingpongFlag = !GetFluidParticlePositionPingPongFlag();
    const uint particleCount = GetFluidParticleCount();

    const uint groupIndex = gid;
    const uint particleIndex = groupIndex * SORT_PARTICLES_KERNEL_SIZE + gi;

    if (particleIndex < particleCount)
    {
        const ParticlePositionIndexed position = GetFluidParticlePosition(particleIndex, pingpongFlag);
        const int3 gridPositionLevel0 = GetKernelMinGridIndex(position.Position);

        if (IsGridInBound(gridPositionLevel0))
        {
            uint3 gridPositionLevel2;
            uint3 gridOffsetLevel1;
            GetFluidGridPositions(gridPositionLevel0, gridPositionLevel2, gridOffsetLevel1);

            const uint blockIndexLevel1Linear = DecodeFluidBlockIndex(FluidGridLevel2[gridPositionLevel2]);
            const uint3 blockIndexLevel1Spatial = GetFluidBlockIndexSpatialLevel1(blockIndexLevel1Linear);

            const uint3 gridIndexLevel1Spatial = blockIndexLevel1Spatial * FLUID_BLOCK_SIZE_LEVEL1 + gridOffsetLevel1;
            const uint blockIndexLevel0Linear = DecodeFluidBlockIndex(FluidGridLevel1[gridIndexLevel1Spatial]);

            const uint particleCountOffset = GetFluidBlockParticleCountOffset(blockIndexLevel0Linear);
            uint dstIndex;
            InterlockedAdd(FluidBlockParticleOffsets[particleCountOffset], -1, dstIndex);

            dstIndex += GetFluidBlockParticleCountPrefixSum(blockIndexLevel0Linear) - 1;

            SetFluidParticlePosition(dstIndex, position, !pingpongFlag);
        }
    }
}

/// end sort particle

/// begin clear/indirect args

#define CLEAR_PARTITION_SUMS_KERNEL_SIZE 128

[numthreads(CLEAR_PARTITION_SUMS_KERNEL_SIZE, 1, 1)]
void ClearPartitionSums(uint3 tid : SV_DispatchThreadID)
{
    const uint partitionCount = GetPartitionCount();
    if (tid.x < partitionCount)
    {
        uint offset = GetPartitionSumOffset(tid.x);
        PartitionSums[offset] = PARTITION_VALUE_NULL;

        offset = GetPartitionInclusiveSumOffset(tid.x);
        PartitionSums[offset] = PARTITION_VALUE_NULL;
    }
}

// layout: {
//   generate particle histogram group count, indirect args{2},
//   sort particles group count, indirect args{2},
//   clear partition sums group count, indirect args{2}
// }
// initial value: { x, 1, 1, x, 1, 1, x, 1, 1 }
extern RWBuffer<uint> IndirectArgs;

uint GetGroupCount(uint nelem, uint kernelSize)
{
    return (nelem + kernelSize - 1) / kernelSize;
}

[numthreads(1, 1, 1)]
void GenerateIndirectArgs0()
{
    const uint poolSize = GetPooledParticlePropertyCount();
    SetPooledParticlePropertyCount(poolSize - min(CurrentFrameAddParticleCount, poolSize));

    const uint particleCount = GetParticleCountLastFrame() + CurrentFrameAddParticleCount;
    SetFluidParticleCount(particleCount);

    IndirectArgs[0] = GetGroupCount(particleCount, GENERATE_PARTICLE_HISTOGRAM_KERNEL_SIZE);
    IndirectArgs[3] = GetGroupCount(particleCount, SORT_PARTICLES_KERNEL_SIZE);

    const uint partitionCount = GetPartitionCount();
    IndirectArgs[6] = GetGroupCount(partitionCount, CLEAR_PARTITION_SUMS_KERNEL_SIZE);

    const bool pingpongFlag = GetFluidParticlePositionPingPongFlag();
    SetFluidParticlePositionPingPongFlag(!pingpongFlag);
}

[numthreads(1, 1, 1)]
void GenerateIndirectArgs1()
{
    const uint blockCount = GetFluidBlockCount(0);
    IndirectArgs[0] = GetGroupCount(blockCount, MAX_PARTITION_SIZE);
}

/// end clear/indirect args

/// begin particle to grid

#define PARTICLE_TO_GRID_KERNEL_SIZE 128

#define FLUID_BLOCK_PADDING 2
#define FLUID_BLOCK_SIZE_LEVEL0_PADDED (FLUID_BLOCK_SIZE_LEVEL0 + FLUID_BLOCK_PADDING)
#define FLUID_BLOCK_GRID_COUNT_LEVEL0_PADDED (FLUID_BLOCK_SIZE_LEVEL0_PADDED * FLUID_BLOCK_SIZE_LEVEL0_PADDED * FLUID_BLOCK_SIZE_LEVEL0_PADDED)

void CalculateWeights(float3 gridToParticle, out float3 weight0, out float3 weight1, out float3 weight2)
{
    weight0 = 0.5 * Square(1.5 - gridToParticle);
    weight1 = 0.75 - Square(gridToParticle - 1.0);
    weight2 = 0.5 * Square(gridToParticle - 0.5);
}

void CalculateParticleGridTransfer(
    float3 particlePosition, uint3 gridPositionLevel1, out float3 blockSpacePos, out uint3 gridIndex,
    out float3 gridToParticle, out float3 weight0, out float3 weight1, out float3 weight2)
{
    blockSpacePos = GetGridSpacePosition(particlePosition) - gridPositionLevel1 * FLUID_BLOCK_SIZE_LEVEL0;
    gridIndex = uint3(GetKernelMinGridIndex(blockSpacePos));
    gridToParticle = blockSpacePos - gridIndex;

    CalculateWeights(gridToParticle, weight0, weight1, weight2);
}

void WaveGetMaxInterval(bool flag, out uint interval, out uint maxInterval)
{
    const uint laneIndex = WaveGetLaneIndex();
    const uint laneCount = WaveGetLaneCount();

    interval = 1;
    uint stride = 1;
    while (stride < laneCount)
    {
        const uint dstLane = laneIndex + stride;
        const bool dstFlag = WaveReadLaneAt(flag, dstLane);

        if (dstLane < laneCount && !dstFlag)
            interval += WaveReadLaneAt(interval, dstLane);

        stride *= 2;
    }

    maxInterval = WaveActiveMax(flag ? interval : 0);
}

groupshared uint3 GridPositionLevel1_GSM;
groupshared uint ParticleCount_GSM;
groupshared uint ParticleOffset_GSM;
// size: 16 * 216 = 3456 bytes
groupshared int4 FluidGrid_GSM[FLUID_BLOCK_GRID_COUNT_LEVEL0_PADDED];
// size: 4 * 216 = 864 bytes
groupshared int SDFGrid_GSM[FLUID_BLOCK_GRID_COUNT_LEVEL0_PADDED];
groupshared uint AdjacentBlockIndexLevel1_GSM[8];

[numthreads(PARTICLE_TO_GRID_KERNEL_SIZE, 1, 1)]
void ParticleToGrid0(uint3 gid : SV_GroupID, uint gi : SV_GroupIndex)
{
    uint i, j, k, l;

    // initialize grid gsm
    for (i = gi; i < FLUID_BLOCK_GRID_COUNT_LEVEL0_PADDED; i += PARTICLE_TO_GRID_KERNEL_SIZE)
    {
        FluidGrid_GSM[i] = int4(0, 0, 0, 0);

        // max sdf
        SDFGrid_GSM[i] = FLUID_GRID_ENCODED_VALUE_MAX;
    }

    if (!gi)
    {
        GetFluidBlockInfo(gid.x, GridPositionLevel1_GSM, ParticleCount_GSM, ParticleOffset_GSM);
    }

    GroupMemoryBarrierWithGroupSync();

    const bool pingpongFlag = GetFluidParticlePositionPingPongFlag();

    // per particle scatter
    #if PARTICLE_TO_GRID_KERNEL_SIZE < FLUID_BLOCK_MAX_PARTICLE_COUNT
        for (i = gi; i < ParticleCount_GSM; i += PARTICLE_TO_GRID_KERNEL_SIZE)
    #else
        if ((i = gi) < ParticleCount_GSM)
    #endif
    {
        // read particle from arrays attached to block
        const uint particleIndex = i + ParticleOffset_GSM;
        const ParticlePositionIndexed position = GetFluidParticlePosition(particleIndex, pingpongFlag);
        const ParticleProperties properties = GetFluidParticleProperties(position.Index);

        const float3 velocity = properties.GetVelocity();
        const float3x3 affine = properties.GetAffine();

        // calculate indices and weights
        float3 blockSpacePos;
        uint3 gridIndex;
        float3 gridToParticle;
        float3 weights[3];
        CalculateParticleGridTransfer(
            position.Position, GridPositionLevel1_GSM, blockSpacePos, gridIndex, gridToParticle,
            weights[0], weights[1], weights[2]);

        const uint gridIndexEncoded = GetFluidBlockGridIndexLinearLevel0(gridIndex, FLUID_BLOCK_PADDING);

        #if !DISABLE_WAVE_SCATTER
            // preparation to handle inter-wave conflicts
            const uint laneIndex = WaveGetLaneIndex();
            const bool isLo = gridIndexEncoded != WaveReadLaneAt(gridIndexEncoded, min(0, laneIndex - 1)) || !laneIndex;

            uint interval, intervalMax;
            WaveGetMaxInterval(isLo, interval, intervalMax);
        #endif

        // simplified mls-mpm p2g
        UNITY_UNROLL
        for (j = 0; j < 3; j++)
        {
            UNITY_UNROLL
            for (k = 0; k < 3; k++)
            {
                UNITY_UNROLL
                for (l = 0; l < 3; l++)
                {
                    const float weight = weights[j].x * weights[k].y * weights[l].z;

                    const float3 x = float3(j, k, l) - gridToParticle;
                    const float3 affineVelocity = mul(affine, x);

                    float4 massMomentum;
                    massMomentum.x = weight * properties.Mass;
                    massMomentum.yzw = massMomentum.x * (velocity + affineVelocity);
                    float sdf = length(x) - FLUID_PARTICLE_RADIUS;

                    #if !DISABLE_WAVE_SCATTER
                        uint stride = 1;
                        while (stride < intervalMax)
                        {
                            const uint dstLane = laneIndex + stride;
                            const float4 tempMassMomentum = WaveReadLaneAt(massMomentum, dstLane);
                            const float tempSDF = WaveReadLaneAt(sdf, dstLane);

                            if (stride < interval)
                            {
                                massMomentum += tempMassMomentum;
                                sdf = SmoothMin(sdf, tempSDF);
                            }

                            stride *= 2;
                        }

                        if (!isLo)
                            continue;
                    #endif

                    const uint dstGridIndexEncoded = gridIndexEncoded + GetFluidBlockGridIndexLinearLevel0(uint3(j, k, l), FLUID_BLOCK_PADDING);
                    const int massEncoded = EncodeFluidGridMass(massMomentum.x);
                    const int3 momentumEncoded = EncodeFluidGridMomentum(massMomentum.yzw);
                    const int sdfEncoded = EncodeFluidGridSDF(sdf);

                    // currently 4-element atomic add is not spported
                    int _;
                    InterlockedAdd(FluidGrid_GSM[dstGridIndexEncoded].x, massEncoded, _);
                    InterlockedAdd(FluidGrid_GSM[dstGridIndexEncoded].y, momentumEncoded.x, _);
                    InterlockedAdd(FluidGrid_GSM[dstGridIndexEncoded].z, momentumEncoded.y, _);
                    InterlockedAdd(FluidGrid_GSM[dstGridIndexEncoded].w, momentumEncoded.z, _);

                    InterlockedMin(SDFGrid_GSM[dstGridIndexEncoded], sdfEncoded, _);
                }
            }
        }
    }

    GroupMemoryBarrierWithGroupSync();

    // write to current block
    const uint3 dstGridOffset = GetFluidBlockIndexSpatialLevel0(gid.x) * FLUID_BLOCK_SIZE_LEVEL0;
    for (i = gi; i < FLUID_BLOCK_GRID_COUNT_LEVEL0; i += PARTICLE_TO_GRID_KERNEL_SIZE)
    {
        const uint3 srcGridIndex = GetFluidBlockGridIndexSpatialLevel0(i);
        const uint loadGridIndex = GetFluidBlockGridIndexLinearLevel0(srcGridIndex, FLUID_BLOCK_PADDING);

        const uint3 dstGridIndex = dstGridOffset +srcGridIndex;

        const int4 gridValue = FluidGrid_GSM[loadGridIndex];

        int _;
        InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL0_OFFSET], gridValue.x, _);
        InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL1_OFFSET], gridValue.y, _);
        InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL2_OFFSET], gridValue.z, _);
        InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL3_OFFSET], gridValue.w, _);
    }

    if (gi < 8)
    {
        const uint3 adjacentGridIndex = uint3(gi & 1, (gi >> 1) & 1, gi >> 2);
        const uint3 adjacentGridPositionLevel1 = adjacentGridIndex + GridPositionLevel1_GSM;
        const uint3 adjacentGridPositionLevel2 = adjacentGridPositionLevel1 / FLUID_BLOCK_SIZE_LEVEL1;
        AdjacentBlockIndexLevel1_GSM[gi] = FluidGridLevel2[adjacentGridPositionLevel2];
    }

    GroupMemoryBarrierWithGroupSync();

    // write to adjacent blocks
    UNITY_UNROLL
    for (i = 1; i < 8; i++)
    {
        // query adjacent block
        const uint3 adjacentGridIndex = uint3(i & 1, (i >> 1) & 1, i >> 2);
        const uint3 adjacentGridPositionLevel1 = adjacentGridIndex + GridPositionLevel1_GSM;
        const uint3 adjacentGridOffsetLevel1 = adjacentGridPositionLevel1 % FLUID_BLOCK_SIZE_LEVEL1;

        const uint adjacentBlockIndexLevel1Encoded = AdjacentBlockIndexLevel1_GSM[i];

        // level 2 doesn't have "ghost cells"(term used in original spgrid paper)
        // thus, if no level 1 block is allocated, grid values are just discarded
        if (IsValidFluidBlockIndex(adjacentBlockIndexLevel1Encoded))
        {
            const uint3 subblockMin = adjacentGridIndex * FLUID_BLOCK_SIZE_LEVEL0;
            const uint3 subblockMax = min(
                subblockMin + FLUID_BLOCK_SIZE_LEVEL0, FLUID_BLOCK_SIZE_LEVEL0_PADDED);
            const uint3 subblockSize = subblockMax - subblockMin;

            const uint3 srcGridIndex = GetGridIndexSpatial(gi, subblockSize.xy);
            if (all(srcGridIndex < subblockSize))
            {
                const uint loadGridIndex = GetFluidBlockGridIndexLinearLevel0(subblockMin + srcGridIndex, FLUID_BLOCK_PADDING);

                const int4 gridValue = FluidGrid_GSM[loadGridIndex];
                const int sdf = SDFGrid_GSM[loadGridIndex];

                const uint3 adjacentBlockIndexLevel1 = GetFluidBlockIndexSpatialLevel1(DecodeFluidBlockIndex(adjacentBlockIndexLevel1Encoded));
                const uint3 adjacentGridIndexLevel1 = adjacentBlockIndexLevel1 * FLUID_BLOCK_SIZE_LEVEL1 + adjacentGridOffsetLevel1;
                const uint3 adjacentBlockIndexLevel0Encoded = FluidGridLevel1[adjacentGridIndexLevel1];

                if (IsValidFluidBlockIndex(adjacentBlockIndexLevel0Encoded))
                {
                    const uint3 adjacentBlockIndexLevel0 = GetFluidBlockIndexSpatialLevel0(DecodeFluidBlockIndex(adjacentBlockIndexLevel0Encoded));
                    const uint3 dstGridIndex = adjacentBlockIndexLevel0 * FLUID_BLOCK_SIZE_LEVEL0 + srcGridIndex;

                    int _;
                    InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL0_OFFSET], gridValue.x, _);
                    InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL1_OFFSET], gridValue.y, _);
                    InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL2_OFFSET], gridValue.z, _);
                    InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL3_OFFSET], gridValue.w, _);
                    InterlockedMin(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL4_OFFSET], sdf, _);
                }
                else
                {
                    // if the level 0 is not allocated, add quantity to the coarser grid
                    const int4 gridValueSum = WaveActiveSum(gridValue);

                    if (!gi)
                    {
                        int _;
                        InterlockedAdd(FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL0_OFFSET], gridValueSum.x, _);
                        InterlockedAdd(FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL1_OFFSET], gridValueSum.y, _);
                        InterlockedAdd(FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL2_OFFSET], gridValueSum.z, _);
                        InterlockedAdd(FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL3_OFFSET], gridValueSum.w, _);
                        InterlockedMin(FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL4_OFFSET], sdf, _);
                    }
                }
            }
        }
    }
}

// size: 12 * 216 = 2592 bytes
groupshared int3 MomentumGridEncoded_GSM[FLUID_BLOCK_GRID_COUNT_LEVEL0_PADDED];
// size: 4 * 216 = 864 bytes
groupshared float MassGrid_GSM[FLUID_BLOCK_GRID_COUNT_LEVEL0_PADDED];

[numthreads(PARTICLE_TO_GRID_KERNEL_SIZE, 1, 1)]
void ParticleToGrid1(uint3 gid : SV_GroupID, uint gi : SV_GroupIndex)
{
    if (!gi)
    {
        GetFluidBlockInfo(gid.x, GridPositionLevel1_GSM, ParticleCount_GSM, ParticleOffset_GSM);
    }

    uint i, j, k, l;

    for (i = gi; i < FLUID_BLOCK_GRID_COUNT_LEVEL0_PADDED; i += PARTICLE_TO_GRID_KERNEL_SIZE)
    {
        MomentumGridEncoded_GSM[i] = int3(0, 0, 0);
    }

    // read mass and velocity from current block
    const uint3 srcGridOffset = GetFluidBlockIndexSpatialLevel0(gid.x) * FLUID_BLOCK_SIZE_LEVEL0;
    for (i = gi; i < FLUID_BLOCK_GRID_COUNT_LEVEL0; i += PARTICLE_TO_GRID_KERNEL_SIZE)
    {
        const uint3 dstGridIndex = GetFluidBlockGridIndexSpatialLevel0(i);
        const uint storeGridIndex = GetFluidBlockGridIndexLinearLevel0(dstGridIndex, FLUID_BLOCK_PADDING);
        const uint3 srcGridIndex = srcGridOffset +dstGridIndex;

        const int massEncoded = FluidGridLevel0[srcGridIndex + FLUID_GRID_CHANNEL0_OFFSET];
        MassGrid_GSM[storeGridIndex] = DecodeFluidGridMass(massEncoded);
    }

    // indices of adjacent blocks to load
    if (gi < 8)
    {
        const uint3 adjacentGridIndex = uint3(gi & 1, (gi >> 1) & 1, gi >> 2);
        const uint3 adjacentGridPositionLevel1 = adjacentGridIndex + GridPositionLevel1_GSM;
        const uint3 adjacentGridPositionLevel2 = adjacentGridPositionLevel1 / FLUID_BLOCK_SIZE_LEVEL1;
        AdjacentBlockIndexLevel1_GSM[gi] = FluidGridLevel2[adjacentGridPositionLevel2];
    }

    GroupMemoryBarrierWithGroupSync();

    // read mass and velocity from adjacent blocks
    UNITY_UNROLL
    for (i = 1; i < 8; i++)
    {
        // query adjacent block
        const uint3 adjacentGridIndex = uint3(i & 1, (i >> 1) & 1, i >> 2);
        const uint3 adjacentGridPositionLevel1 = adjacentGridIndex + GridPositionLevel1_GSM;
        const uint3 adjacentGridOffsetLevel1 = adjacentGridPositionLevel1 % FLUID_BLOCK_SIZE_LEVEL1;

        const uint adjacentBlockIndexLevel1Encoded = AdjacentBlockIndexLevel1_GSM[i];

        const uint3 subblockMin = adjacentGridIndex * FLUID_BLOCK_SIZE_LEVEL0;
        const uint3 subblockMax = min(
            subblockMin + FLUID_BLOCK_SIZE_LEVEL0, FLUID_BLOCK_SIZE_LEVEL0_PADDED);
        const uint3 subblockSize = subblockMax - subblockMin;

        const uint3 dstGridIndex = GetGridIndexSpatial(gi, subblockSize.xy);
        const uint storeGridIndex = GetFluidBlockGridIndexLinearLevel0(subblockMin + dstGridIndex, FLUID_BLOCK_PADDING);

        // level 2 doesn't have "ghost cells"(terms used in original spgrid paper)
        // thus, if no level 1 block is allocated, grid values are just discarded
        if (all(dstGridIndex < subblockSize))
        {
            if (IsValidFluidBlockIndex(adjacentBlockIndexLevel1Encoded))
            {
                const uint3 adjacentBlockIndexLevel1 = GetFluidBlockIndexSpatialLevel1(DecodeFluidBlockIndex(adjacentBlockIndexLevel1Encoded));
                const uint3 adjacentGridIndexLevel1 = adjacentBlockIndexLevel1 * FLUID_BLOCK_SIZE_LEVEL1 + adjacentGridOffsetLevel1;
                const uint3 adjacentBlockIndexLevel0Encoded = FluidGridLevel1[adjacentGridIndexLevel1];

                int massEncoded;
                if (IsValidFluidBlockIndex(adjacentBlockIndexLevel0Encoded))
                {
                    const uint3 adjacentBlockIndexLevel0 = GetFluidBlockIndexSpatialLevel0(DecodeFluidBlockIndex(adjacentBlockIndexLevel0Encoded));
                    const uint3 srcGridIndex = adjacentBlockIndexLevel0 * FLUID_BLOCK_SIZE_LEVEL0 + dstGridIndex;

                    massEncoded = FluidGridLevel0[srcGridIndex + FLUID_GRID_CHANNEL0_OFFSET];
                }
                else
                {
                    // if the level 0 is not allocated, read from the coarser grid
                    massEncoded = FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL0_OFFSET];
                }

                MassGrid_GSM[storeGridIndex] = DecodeFluidGridMass(massEncoded);
            }
            else
            {
                MassGrid_GSM[storeGridIndex] = 0.0;
            }
        }
    }

    GroupMemoryBarrierWithGroupSync();

    const bool pingpongFlag = GetFluidParticlePositionPingPongFlag();

    // read particles from current block
    #if PARTICLE_TO_GRID_KERNEL_SIZE < FLUID_BLOCK_MAX_PARTICLE_COUNT
        for (i = gi; i < ParticleCount_GSM; i += PARTICLE_TO_GRID_KERNEL_SIZE)
    #else
        if ((i = gi) < ParticleCount_GSM)
    #endif
    {
        // particles have been sorted into a linear array in particle-to-grid transfer.
        // thus they can be indexed without per-particle indirection.
        const uint particleIndex = ParticleOffset_GSM + i;

        ParticlePositionIndexed position = GetFluidParticlePosition(particleIndex, pingpongFlag);
        ParticleProperties properties = GetFluidParticleProperties(position.Index);

        float3 blockSpacePos;
        uint3 gridIndexOffset;
        float3 gridToParticleOffset;
        float3 weights[3];
        CalculateParticleGridTransfer(
            position.Position, GridPositionLevel1_GSM, blockSpacePos, gridIndexOffset, gridToParticleOffset,
            weights[0], weights[1], weights[2]);

        const uint gridIndexOffsetEncoded = GetFluidBlockGridIndexLinearLevel0(gridIndexOffset, FLUID_BLOCK_PADDING);

        float density = 0.0;
        for (j = 0; j < 3; j++)
        {
            for (k = 0; k < 3; k++)
            {
                for (l = 0; l < 3; l++)
                {
                    const float weight = weights[j].x * weights[k].y * weights[l].z;
                    const uint gridIndexEncoded = gridIndexOffsetEncoded + GetFluidBlockGridIndexLinearLevel0(uint3(j, k, l), FLUID_BLOCK_PADDING);

                    const float mass = MassGrid_GSM[gridIndexEncoded];
                    density += weight * mass;
                }
            }
        }

        // tait-murnaghan equation of state
        const float pressure = (FLUID_EOS_BULK_MODULUS * 0.25) * Pow4(density * (1.0 / FLUID_EOS_REST_DENSITY));
        const float volume = properties.Mass / density;
        const float3x3 affine = properties.GetAffine();

        float3x3 stress = FLUID_VISCOSITY_COEFFICIENT * (affine + transpose(affine));
        stress._m00 -= pressure;
        stress._m11 -= pressure;
        stress._m22 -= pressure;

        const float3x3 c = 3.0 * TIME_STEP * volume * stress;

        #if !DISABLE_WAVE_SCATTER
            // preparation to handle inter-wave conflicts
            const uint laneIndex = WaveGetLaneIndex();
            const bool isLo = gridIndexOffset != WaveReadLaneAt(gridIndexOffset, min(0, laneIndex - 1)) || !laneIndex;

            uint interval, intervalMax;
            WaveGetMaxInterval(isLo, interval, intervalMax);
        #endif

        UNITY_UNROLL
        for (j = 0; j < 3; j++)
        {
            UNITY_UNROLL
            for (k = 0; k < 3; k++)
            {
                UNITY_UNROLL
                for (l = 0; l < 3; l++)
                {
                    const float weight = weights[j].x * weights[k].y * weights[l].z;
                    const float3 gridToParticle = gridToParticleOffset -float3(j, k, l);
                    float3 momentum = weight * mul(c, gridToParticle);

                    #if !DISABLE_WAVE_SCATTER
                        uint stride = 1;
                        while (stride < intervalMax)
                        {
                            const uint dstLane = laneIndex + stride;
                            const float3 tempMomentum = WaveReadLaneAt(momentum, dstLane);

                            if (stride < interval)
                                momentum += tempMomentum;

                            stride *= 2;
                        }

                        if (!isLo)
                            continue;
                    #endif

                    const uint dstGridIndexEncoded = gridIndexOffsetEncoded + GetFluidBlockGridIndexLinearLevel0(uint3(j, k, l), FLUID_BLOCK_PADDING);
                    const int3 momentumEncoded = EncodeFluidGridMomentum(momentum);

                    int _;
                    InterlockedAdd(MomentumGridEncoded_GSM[dstGridIndexEncoded].x, momentumEncoded.x, _);
                    InterlockedAdd(MomentumGridEncoded_GSM[dstGridIndexEncoded].y, momentumEncoded.y, _);
                    InterlockedAdd(MomentumGridEncoded_GSM[dstGridIndexEncoded].z, momentumEncoded.z, _);
                }
            }
        }
    }

    GroupMemoryBarrierWithGroupSync();

    // write momentum to current blocks
    const uint3 dstGridOffset = GetFluidBlockIndexSpatialLevel0(gid.x) * FLUID_BLOCK_SIZE_LEVEL0;
    for (i = gi; i < FLUID_BLOCK_GRID_COUNT_LEVEL0; i += PARTICLE_TO_GRID_KERNEL_SIZE)
    {
        const uint3 srcGridIndex = GetFluidBlockGridIndexSpatialLevel0(i);
        const uint loadGridIndex = GetFluidBlockGridIndexLinearLevel0(srcGridIndex, FLUID_BLOCK_PADDING);

        const uint3 dstGridIndex = dstGridOffset +srcGridIndex;

        const int3 gridValue = MomentumGridEncoded_GSM[loadGridIndex];

        int _;
        InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL1_OFFSET], gridValue.x, _);
        InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL2_OFFSET], gridValue.y, _);
        InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL3_OFFSET], gridValue.z, _);
    }

    // write to adjacent blocks
    UNITY_UNROLL
    for (i = 1; i < 8; i++)
    {
        // query adjacent block
        const uint3 adjacentGridIndex = uint3(i & 1, (i >> 1) & 1, i >> 2);
        const uint3 adjacentGridPositionLevel1 = adjacentGridIndex + GridPositionLevel1_GSM;
        const uint3 adjacentGridOffsetLevel1 = adjacentGridPositionLevel1 % FLUID_BLOCK_SIZE_LEVEL1;

        const uint adjacentBlockIndexLevel1Encoded = AdjacentBlockIndexLevel1_GSM[i];

        // level 2 doesn't have "ghost cells"(term used in original spgrid paper)
        // thus, if no level 1 block is allocated, grid values are just discarded
        if (IsValidFluidBlockIndex(adjacentBlockIndexLevel1Encoded))
        {
            const uint3 subblockMin = adjacentGridIndex * FLUID_BLOCK_SIZE_LEVEL0;
            const uint3 subblockMax = min(
                subblockMin + FLUID_BLOCK_SIZE_LEVEL0, FLUID_BLOCK_SIZE_LEVEL0_PADDED);
            const uint3 subblockSize = subblockMax - subblockMin;

            const uint3 srcGridIndex = GetGridIndexSpatial(gi, subblockSize.xy);
            if (all(srcGridIndex < subblockSize))
            {
                const uint loadGridIndex = GetFluidBlockGridIndexLinearLevel0(subblockMin + srcGridIndex, FLUID_BLOCK_PADDING);

                const int3 gridValue = MomentumGridEncoded_GSM[loadGridIndex];

                const uint3 adjacentBlockIndexLevel1 = GetFluidBlockIndexSpatialLevel1(DecodeFluidBlockIndex(adjacentBlockIndexLevel1Encoded));
                const uint3 adjacentGridIndexLevel1 = adjacentBlockIndexLevel1 * FLUID_BLOCK_SIZE_LEVEL1 + adjacentGridOffsetLevel1;
                const uint3 adjacentBlockIndexLevel0Encoded = FluidGridLevel1[adjacentGridIndexLevel1];

                if (IsValidFluidBlockIndex(adjacentBlockIndexLevel0Encoded))
                {
                    const uint3 adjacentBlockIndexLevel0 = GetFluidBlockIndexSpatialLevel0(DecodeFluidBlockIndex(adjacentBlockIndexLevel0Encoded));
                    const uint3 dstGridIndex = adjacentBlockIndexLevel0 * FLUID_BLOCK_SIZE_LEVEL0 + srcGridIndex;

                    int _;
                    InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL1_OFFSET], gridValue.x, _);
                    InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL2_OFFSET], gridValue.y, _);
                    InterlockedAdd(FluidGridLevel0[dstGridIndex + FLUID_GRID_CHANNEL3_OFFSET], gridValue.z, _);
                }
                else
                {
                    // if the level 0 is not allocated, add quantity to the coarser grid
                    const int3 gridValueSum = WaveActiveSum(gridValue);

                    if (!gi)
                    {
                        int _;
                        InterlockedAdd(FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL1_OFFSET], gridValueSum.x, _);
                        InterlockedAdd(FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL2_OFFSET], gridValueSum.y, _);
                        InterlockedAdd(FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL3_OFFSET], gridValueSum.z, _);
                    }
                }
            }
        }
    }
}

/// end particle to grid

/// begin solve grid

#define SOLVE_GRID_LEVEL0_KERNEL_SIZE FLUID_BLOCK_SIZE_LEVEL0
#define SOLVE_GRID_LEVEL1_KERNEL_SIZE FLUID_BLOCK_SIZE_LEVEL1

SamplerState SamplerLinearClamp;
#define SCENE_VOLUME_SAMPLER SamplerLinearClamp

#include "../Graphics/SceneVolumeSampling.cginc"

void SolveGrid(float mass, float3 momentum, out float3 velocity)
{
    velocity = mass > 0.0 ? momentum / mass : 0.0;
    velocity += TIME_STEP * GLOBAL_GRAVITY;

    // todo
    // apply boundary condition here

}

[numthreads(SOLVE_GRID_LEVEL0_KERNEL_SIZE, SOLVE_GRID_LEVEL0_KERNEL_SIZE, SOLVE_GRID_LEVEL0_KERNEL_SIZE)]
void SolveGridLevel0(uint3 gid : SV_GroupID, uint3 gtid : SV_GroupThreadID)
{
    const uint3 blockIndex = GetFluidBlockIndexSpatialLevel0(gid.x);
    const uint3 gridIndex = blockIndex * FLUID_BLOCK_SIZE_LEVEL0 + gtid;

    const int massEncoded = FluidGridLevel0[gridIndex + FLUID_GRID_CHANNEL0_OFFSET];
    const int3 momentumEncoded = int3(
        FluidGridLevel0[gridIndex + FLUID_GRID_CHANNEL1_OFFSET],
        FluidGridLevel0[gridIndex + FLUID_GRID_CHANNEL2_OFFSET],
        FluidGridLevel0[gridIndex + FLUID_GRID_CHANNEL3_OFFSET]);

    const float mass = DecodeFluidGridMass(massEncoded);
    const float3 momentum = DecodeFluidGridMomentum(momentumEncoded);

    float3 velocity = 0.0;
    SolveGrid(mass, momentum, velocity);

    // const uint3 gridPosition = GetFluidBlockPosition(gid.x) * FLUID_BLOCK_SIZE_LEVEL0 + gtid;
    // const float3 positionSDFSpace = gridPosition + FluidGridToSDF;
    // const float3 sdfSampleLocation = positionSDFSpace * SCENE_VOLUME_TEXEL;
    // if (all(sdfSampleLocation > 0.0 && sdfSampleLocation < 1.0))
    // {
    //     const float nsdf = SampleNormalizedSDF(sdfSampleLocation, 0.0);
    //     if (nsdf <= 0.0)
    //     {
    //         const float3 normal = SampleNormal(sdfSampleLocation, 0.0);

    //         velocity -= dot(velocity, normal) * normal;
    //     }
    // }

    const int3 velocityEncoded = EncodeFluidGridMomentum(velocity);
    FluidGridLevel0[gridIndex + FLUID_GRID_CHANNEL1_OFFSET] = velocityEncoded.x;
    FluidGridLevel0[gridIndex + FLUID_GRID_CHANNEL2_OFFSET] = velocityEncoded.y;
    FluidGridLevel0[gridIndex + FLUID_GRID_CHANNEL3_OFFSET] = velocityEncoded.z;
}

[numthreads(SOLVE_GRID_LEVEL1_KERNEL_SIZE, SOLVE_GRID_LEVEL1_KERNEL_SIZE, SOLVE_GRID_LEVEL1_KERNEL_SIZE)]
void SolveGridLevel1(uint3 gid : SV_GroupID, uint3 gtid : SV_GroupThreadID)
{
    const uint3 blockIndex = GetFluidBlockIndexSpatialLevel1(gid.x);
    const uint3 gridIndex = blockIndex * FLUID_BLOCK_SIZE_LEVEL1 + gtid;

    const int massEncoded = FluidGridLevel1[gridIndex + FLUID_GRID_CHANNEL0_OFFSET];
    if (!IsValidFluidBlockIndex(massEncoded))
    {
        const int3 momentumEncoded = int3(
            FluidGridLevel1[gridIndex + FLUID_GRID_CHANNEL1_OFFSET],
            FluidGridLevel1[gridIndex + FLUID_GRID_CHANNEL2_OFFSET],
            FluidGridLevel1[gridIndex + FLUID_GRID_CHANNEL3_OFFSET]);

        const float mass = DecodeFluidGridMass(massEncoded);
        const float3 momentum = DecodeFluidGridMomentum(momentumEncoded);

        float3 velocity;
        SolveGrid(mass, momentum, velocity);

        const int3 velocityEncoded = EncodeFluidGridMomentum(velocity);

        FluidGridLevel1[gridIndex + FLUID_GRID_CHANNEL1_OFFSET] = velocityEncoded.x;
        FluidGridLevel1[gridIndex + FLUID_GRID_CHANNEL2_OFFSET] = velocityEncoded.y;
        FluidGridLevel1[gridIndex + FLUID_GRID_CHANNEL3_OFFSET] = velocityEncoded.z;
    }
}

/// end solve grid

/// begin grid to particle

#define GRID_TO_PARTICLE_KERNEL_SIZE 128

groupshared float3 VelocityGrid_GSM[FLUID_BLOCK_GRID_COUNT_LEVEL0_PADDED];

[numthreads(GRID_TO_PARTICLE_KERNEL_SIZE, 1, 1)]
void GridToParticle(uint3 gid : SV_GroupID, uint gi : SV_GroupIndex)
{
    if (!gi)
    {
        GetFluidBlockInfo(gid.x, GridPositionLevel1_GSM, ParticleCount_GSM, ParticleOffset_GSM);
    }

    uint i, j, k, l;

    // read from current block
    const uint3 srcGridOffset = GetFluidBlockIndexSpatialLevel0(gid.x) * FLUID_BLOCK_SIZE_LEVEL0;
    for (i = gi; i < FLUID_BLOCK_GRID_COUNT_LEVEL0; i += GRID_TO_PARTICLE_KERNEL_SIZE)
    {
        const uint3 dstGridIndex = GetFluidBlockGridIndexSpatialLevel0(i);
        const uint storeGridIndex = GetFluidBlockGridIndexLinearLevel0(dstGridIndex, FLUID_BLOCK_PADDING);
        const uint3 srcGridIndex = srcGridOffset +dstGridIndex;

        const int3 velocityEncoded = int3(
            FluidGridLevel0[srcGridIndex + FLUID_GRID_CHANNEL1_OFFSET],
            FluidGridLevel0[srcGridIndex + FLUID_GRID_CHANNEL2_OFFSET],
            FluidGridLevel0[srcGridIndex + FLUID_GRID_CHANNEL3_OFFSET]);

        VelocityGrid_GSM[storeGridIndex] = DecodeFluidGridMomentum(velocityEncoded);
    }

    // indices of adjacent blocks to load
    if (gi < 8)
    {
        const uint3 adjacentGridIndex = uint3(gi & 1, (gi >> 1) & 1, gi >> 2);
        const uint3 adjacentGridPositionLevel1 = adjacentGridIndex + GridPositionLevel1_GSM;
        const uint3 adjacentGridPositionLevel2 = adjacentGridPositionLevel1 / FLUID_BLOCK_SIZE_LEVEL1;
        AdjacentBlockIndexLevel1_GSM[gi] = FluidGridLevel2[adjacentGridPositionLevel2];
    }

    GroupMemoryBarrierWithGroupSync();

    // read velocity from adjacent blocks
    UNITY_UNROLL
    for (i = 1; i < 8; i++)
    {
        // query adjacent block
        const uint3 adjacentGridIndex = uint3(i & 1, (i >> 1) & 1, i >> 2);
        const uint3 adjacentGridPositionLevel1 = adjacentGridIndex + GridPositionLevel1_GSM;
        const uint3 adjacentGridOffsetLevel1 = adjacentGridPositionLevel1 % FLUID_BLOCK_SIZE_LEVEL1;

        const uint adjacentBlockIndexLevel1Encoded = AdjacentBlockIndexLevel1_GSM[i];

        const uint3 subblockMin = adjacentGridIndex * FLUID_BLOCK_SIZE_LEVEL0;
        const uint3 subblockMax = min(
            subblockMin + FLUID_BLOCK_SIZE_LEVEL0, FLUID_BLOCK_SIZE_LEVEL0_PADDED);
        const uint3 subblockSize = subblockMax - subblockMin;

        const uint3 dstGridIndex = GetGridIndexSpatial(gi, subblockSize.xy);
        const uint storeGridIndex = GetFluidBlockGridIndexLinearLevel0(subblockMin + dstGridIndex, FLUID_BLOCK_PADDING);

        // level 2 doesn't have "ghost cells"(terms used in original spgrid paper)
        // thus, if no level 1 block is allocated, grid values are just discarded
        if (all(dstGridIndex < subblockSize))
        {
            if (IsValidFluidBlockIndex(adjacentBlockIndexLevel1Encoded))
            {
                const uint3 adjacentBlockIndexLevel1 = GetFluidBlockIndexSpatialLevel1(DecodeFluidBlockIndex(adjacentBlockIndexLevel1Encoded));
                const uint3 adjacentGridIndexLevel1 = adjacentBlockIndexLevel1 * FLUID_BLOCK_SIZE_LEVEL1 + adjacentGridOffsetLevel1;
                const uint3 adjacentBlockIndexLevel0Encoded = FluidGridLevel1[adjacentGridIndexLevel1];

                int3 velocityEncoded;
                if (IsValidFluidBlockIndex(adjacentBlockIndexLevel0Encoded))
                {
                    const uint3 adjacentBlockIndexLevel0 = GetFluidBlockIndexSpatialLevel0(DecodeFluidBlockIndex(adjacentBlockIndexLevel0Encoded));
                    const uint3 srcGridIndex = adjacentBlockIndexLevel0 * FLUID_BLOCK_SIZE_LEVEL0 + dstGridIndex;

                    velocityEncoded = int3(
                        FluidGridLevel0[srcGridIndex + FLUID_GRID_CHANNEL1_OFFSET],
                        FluidGridLevel0[srcGridIndex + FLUID_GRID_CHANNEL2_OFFSET],
                        FluidGridLevel0[srcGridIndex + FLUID_GRID_CHANNEL3_OFFSET]);
                }
                else
                {
                    // if the level 0 is not allocated, read from the coarser grid
                    velocityEncoded = int3(
                        FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL1_OFFSET],
                        FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL2_OFFSET],
                        FluidGridLevel1[adjacentGridIndexLevel1 + FLUID_GRID_CHANNEL3_OFFSET]);
                }

                VelocityGrid_GSM[storeGridIndex] = DecodeFluidGridMomentum(velocityEncoded);
            }
            else
            {
                VelocityGrid_GSM[storeGridIndex] = GLOBAL_GRAVITY * TIME_STEP;
            }
        }
    }

    GroupMemoryBarrierWithGroupSync();

    // take complementary since particles are sorted into another ping-pong buffer in p2g
    const bool pingpongFlag = GetFluidParticlePositionPingPongFlag();

    // per particle gather
    #if GRID_TO_PARTICLE_KERNEL_SIZE < FLUID_BLOCK_MAX_PARTICLE_COUNT
        for (i = gi; i < ParticleCount_GSM; i += GRID_TO_PARTICLE_KERNEL_SIZE)
    #else
        if ((i = gi) < ParticleCount_GSM)
    #endif
    {
        // particles have been sorted into a linear array in particle-to-grid transfer.
        // thus they can be indexed without per-particle indirection.
        const uint particleIndex = ParticleOffset_GSM + i;

        ParticlePositionIndexed position = GetFluidParticlePosition(particleIndex, pingpongFlag);

        float3 blockSpacePos;
        uint3 gridIndexOffset;
        float3 gridToParticleOffset;
        float3 weights[3];
        CalculateParticleGridTransfer(
            position.Position, GridPositionLevel1_GSM, blockSpacePos, gridIndexOffset, gridToParticleOffset,
            weights[0], weights[1], weights[2]);

        const uint gridIndexOffsetEncoded = GetFluidBlockGridIndexLinearLevel0(gridIndexOffset, FLUID_BLOCK_PADDING);

        float3x3 affine = 0.0;
        float3 velocity = 0.0;
        UNITY_UNROLL
        for (j = 0; j < 3; j++)
        {
            UNITY_UNROLL
            for (k = 0; k < 3; k++)
            {
                UNITY_UNROLL
                for (l = 0; l < 3; l++)
                {
                    const float weight = weights[j].x * weights[k].y * weights[l].z;

                    const uint gridIndexEncoded = gridIndexOffsetEncoded + GetFluidBlockGridIndexLinearLevel0(uint3(j, k, l), FLUID_BLOCK_PADDING);
                    const float3 weightedVelocity = weight * VelocityGrid_GSM[gridIndexEncoded];

                    const float3 gridToParticle = gridToParticleOffset -float3(j, k, l);
                    affine += float3x3(
                        gridToParticle * weightedVelocity.x,
                        gridToParticle * weightedVelocity.y,
                        gridToParticle * weightedVelocity.z);

                    velocity += weightedVelocity;
                }
            }
        }

        position.Position += velocity * TIME_STEP;

        // move particle out of implicit surface
        const float3 positionSDFSpace = position.Position - FluidGridTranslation + FluidGridToSDF;
        const float3 sdfSampleLocation = positionSDFSpace * SCENE_VOLUME_TEXEL;
        if (all(sdfSampleLocation > 0.0 && sdfSampleLocation < 1.0))
        {
            const float nsdf = SampleNormalizedSDF(sdfSampleLocation, 0.0);
            if (nsdf <= 0.0)
            {
                const float sdf = nsdf * 4.0;
                const float3 normal = SampleNormal(sdfSampleLocation, 0.0);
                const float3 displacement = -sdf * normal;

                position.Position += displacement;
                velocity += displacement * TIME_STEP_INV;
            }
        }

        SetFluidParticlePosition(particleIndex, position, pingpongFlag);
        SetFluidParticleAffineVelocity(position.Index, affine, velocity);
    }
}

/// end grid to particle

/// begin clear fluid grid

#define CLEAR_FLUID_GRID_LEVEL0_KERNEL_SIZE FLUID_BLOCK_SIZE_LEVEL0

[numthreads(CLEAR_FLUID_GRID_LEVEL0_KERNEL_SIZE, CLEAR_FLUID_GRID_LEVEL0_KERNEL_SIZE, CLEAR_FLUID_GRID_LEVEL0_KERNEL_SIZE)]
void ClearFluidGridLevel0(uint3 gid : SV_GroupID, uint3 gtid : SV_GroupThreadID)
{
    const uint3 blockIndex = GetFluidBlockIndexSpatialLevel0(gid.x);
    const uint3 gridOffset = blockIndex * FLUID_BLOCK_SIZE_LEVEL0 + gtid;

    FluidGridLevel0[gridOffset +FLUID_GRID_CHANNEL0_OFFSET] = 0;
    FluidGridLevel0[gridOffset +FLUID_GRID_CHANNEL1_OFFSET] = 0;
    FluidGridLevel0[gridOffset +FLUID_GRID_CHANNEL2_OFFSET] = 0;
    FluidGridLevel0[gridOffset +FLUID_GRID_CHANNEL3_OFFSET] = 0;
    FluidGridLevel0[gridOffset +FLUID_GRID_CHANNEL4_OFFSET] = 0;
}

#define CLEAR_FLUID_GRID_LEVEL1_KERNEL_SIZE FLUID_BLOCK_SIZE_LEVEL1

[numthreads(CLEAR_FLUID_GRID_LEVEL1_KERNEL_SIZE, CLEAR_FLUID_GRID_LEVEL1_KERNEL_SIZE, CLEAR_FLUID_GRID_LEVEL1_KERNEL_SIZE)]
void ClearFluidGridLevel1(uint3 gid : SV_GroupID, uint3 gtid : SV_GroupThreadID)
{
    const uint3 blockIndex = GetFluidBlockIndexSpatialLevel1(gid.x);
    const uint3 gridOffset = blockIndex * FLUID_BLOCK_SIZE_LEVEL1 + gtid;

    FluidGridLevel1[gridOffset +FLUID_GRID_CHANNEL0_OFFSET] = 0;
    FluidGridLevel1[gridOffset +FLUID_GRID_CHANNEL1_OFFSET] = 0;
    FluidGridLevel1[gridOffset +FLUID_GRID_CHANNEL2_OFFSET] = 0;
    FluidGridLevel1[gridOffset +FLUID_GRID_CHANNEL3_OFFSET] = 0;
    FluidGridLevel1[gridOffset +FLUID_GRID_CHANNEL4_OFFSET] = 0;
}

/// end clear fluid grid

/// begin add particle

#define ADD_PARTICLES_KERNEL_SIZE 128

CBUFFER_START(AddParticlesParameters)
    uint AddParticleCount;

    float Mass;
CBUFFER_END

extern ByteAddressBuffer ParticlesToAdd;

[numthreads(ADD_PARTICLES_KERNEL_SIZE, 1, 1)]
void AddParticles(uint3 tid : SV_DispatchThreadID)
{
    if (tid.x >= AddParticleCount)
        return;

    const uint poolSize = GetPooledParticlePropertyCount();
    const uint prevParticleCount = GetParticleCountLastFrame();

    uint propertyIndex;
    if (tid.x < poolSize)
        propertyIndex = GetPooledParticleProperty(poolSize - 1 - tid.x);
    else
        propertyIndex = tid.x + prevParticleCount;

    ParticlePositionIndexed position;
    ParticleProperties properties;

    const float4 word0 = asfloat(ParticlesToAdd.Load4(tid.x * 24));
    const float2 word1 = asfloat(ParticlesToAdd.Load2(tid.x * 24 + 16));

    position.Position = word0.xyz;
    position.Index = propertyIndex;

    properties.SetVelocity(float3(word0.w, word1));
    properties.SetZeroAffine();
    properties.Mass = Mass;

    // write to next ping pong buffer in advance
    const bool pingpongFlag = GetFluidParticlePositionPingPongFlag();
    SetFluidParticlePosition(prevParticleCount + tid.x, position, !pingpongFlag);
    SetFluidParticleProperties(propertyIndex, properties);
}

/// end add particle
